1/26
General set up, ran LR model. 
- 69% accuracy, .22 MCC
Added class_weight=balanced
- 57% accuracy, .27 MCC
Brief intuition: 
# The following line penalizes the model for making mistakes on minority classes
# This can be useful because we have very imbalanced data (I think)
# The model focuses more on minority classes, 
#       which reduces accuracy (as it's more focused on the less likely cases)
# but does improve the mcc, which cares about the classes in a more equal way 
# So, accuracy goes from .69 -> .57 but mcc goes from .22 -> .27
# Overarching question is: "Which metrics do we care about? Which ones mean our model is better?"
#       As a side thing, we could try seeing what the metrics for something pre-built is (BERT, HuggingFace etc), and use their 
#       performance in these stats to get a general idea of what we're aiming for 
#       (eg, if BERT has low accuracy but high mcc, maybe that means the model is better, if we can justify this)
# model = LogisticRegression(class_weight='balanced', max_iter=1000)

1/27
Wrote datasetAnalysis.py to visualize data breakdown
- 68% of reviews are 5 star reviews, meaning 68% accuracy can be achieved if 
    the model overfits the data and just predicts all ratings to be 5 stars
Began work on Naive Bayes
- MCC = 0.0 (error?), Accuracy = .67 (ass)
    - MCC is not an error, the model overfits, and predicts 5 for every vector
    - But wait, why is accuracy .67 when we established that predicting all 5 stars would result in .68 accruacy?
        - Because the accuracy is based on the testing data, a random sample, so the actual accuracy may slightly skew in either direction
Started using classificationReport() for testing
    -MCC is based off of TP, TN, FP, FN, all of which influence the reliability score. Currently, the model is exhbiting a high number of false positive predictions.
        Specifically, the model will incorrectly predict a 5 star rating when the actual value tends to be lower.
        Overall, this is decreasing the mcc, since many 3 and 4 stars ratings are predicted to be 5 stars.
        As mentioned above, this is actually occuring for every rating that is not 5 stars i.e. the model currently predicts any rating to be 5 stars

Use CNB, docs says good for imbalanced datasets
- Doesn't really work better out of the box (improve?)